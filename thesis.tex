%% License 
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %% This is licensed under the terms of the MIT license below.                 %%
  %%                                                                            %%
  %% Written by Luis R.J. Costa.                                                %%
  %% Currently developed at the Learning Services of Aalto University School of %%
  %% Electrical Engineering by Luis R.J. Costa since May 2017.                  %%
  %%                                                                            %%
  %% Copyright 2017-2018, by Luis R.J. Costa, luis.costa@aalto.fi,              %%
  %% Copyright 2017-2018 Swedish translations in aaltothesis.cls by Elisabeth   %%
  %% Nyberg, elisabeth.nyberg@aalto.fi and Henrik Wallén,                       %%
  %% henrik.wallen@aalto.fi.                                                    %%
  %% Copyright 2017-2018 Finnish documentation in the template opinnatepohja.tex%%
  %% by Perttu Puska, perttu.puska@aalto.fi, and Luis R.J. Costa.               %%
  %% Copyright 2018 English template thesistemplate.tex by Luis R.J. Costa.     %%
  %% Copyright 2018 Swedish template kandidatarbetsbotten.tex by Henrik Wallen. %%
  %%                                                                            %%
  %% Permission is hereby granted, free of charge, to any person obtaining a    %%
  %% copy of this software and associated documentation files (the "Software"), %%
  %% to deal in the Software without restriction, including without limitation  %%
  %% the rights to use, copy, modify, merge, publish, distribute, sublicense,   %%
  %% and/or sell copies of the Software, and to permit persons to whom the      %%
  %% Software is furnished to do so, subject to the following conditions:       %%
  %% The above copyright notice and this permission notice shall be included in %%
  %% all copies or substantial portions of the Software.                        %%
  %% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR %%
  %% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   %%
  %% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    %%
  %% THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER %%
  %% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    %%
  %% FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        %%
  %% DEALINGS IN THE SOFTWARE.                                                  %%
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%

%% spellcheck-on

%% Configurations, meta information, prefaces etc. 
  \documentclass[english, 12pt, a4paper, elec, utf8, a-1b, hidelinks]{aaltothesis}
  %\documentclass[english, 12pt, a4paper, elec, utf8, a-1b]{aaltothesis}
  %\documentclass[english, 12pt, a4paper, elec, dvips, online]{aaltothesis}

  %% Use the following options in the \documentclass macro above:
  %% your school: arts, biz, chem, elec, eng, sci
  %% the character encoding scheme used by your editor: utf8, latin1
  %% thesis language: english, finnish, swedish
  %% make an archiveable PDF/A-1b or PDF/A-2b compliant file: a-1b, a-2b
  %%                    (with pdflatex, a normal pdf containing metadata is
  %%                     produced without the a-*b option)
  %% typeset in symmetric layout and blue hypertext for online publication: online
  %%            (no option is the default, resulting in a wide margin on the
  %%             binding side of the page and black hypertext)
  %% two-sided printing: twoside (default is one-sided printing)

  \usepackage{amsfonts, amssymb, amsbsy, amsmath, natbib, graphicx}

  \DeclareMathOperator*{\argmax}{argmax}

  % \university{Aalto-yliopisto}
  % \school{Sähkötekniikan korkeakoulu}
  \degreeprogram{Computer, Communication and Information Sciences}
  \major{Signal, Speech and Language Processing}
  \code{ELEC3031}
  \univdegree{MSc}
  \thesisauthor{Anssi Moisio}

  %% A possible "and" in the title should not be the last word in the line, it
  %% begins the next line.
  %% Specify the title again without the linebreak characters in the optional
  %% argument in box brackets. This is done because the title is part of the 
  %% metadata in the pdf/a file, and the metadata cannot contain linebreaks.
  \thesistitle{Recognising Finnish conversations} % working title
  %\thesistitle[Title of the thesis]{Title of\\ the thesis}
  \place{Espoo}
  \date{}

  %% Thesis supervisor
  %% Note the "\" character in the title after the period and before the space
  %% and the following character string.
  %% This is because the period is not the end of a sentence after which a
  %% slightly longer space follows, but what is desired is a regular interword
  %% space.
  \supervisor{Prof.\ Mikko Kurimo}

  %% Advisor(s)---two at the most---of the thesis.
  \advisor{Dr.}

  %% Aaltologo: syntax:
  %% \uselogo{aaltoRed|aaltoBlue|aaltoYellow|aaltoGray|aaltoGrayScale}{?|!|''}
  %% The logo language is set to be the same as the thesis language.
  \uselogo{aaltoRed}{''}

  %% The English abstract:
  %% All the details (name, title, etc.) on the abstract page appear as specified
  %% above.
  %% Thesis keywords:
  %% Note! The keywords are separated using the \spc macro
  \keywords{For keywords choose\spc concepts that are\spc central to your\spc thesis}

  %% The abstract text. This text is included in the metadata of the pdf file as well
  %% as the abstract page.
  \thesisabstract{abstract here
  }

  %% Copyright text. Copyright of a work is with the creator/author of the work
  %% regardless of whether the copyright mark is explicitly in the work or not.
  %% You may, if you wish, publish your work under a Creative Commons license (see
  %% creaticecommons.org), in which case the license text must be visible in the
  %% work. Write here the copyright text you want. It is written into the metadata
  %% of the pdf file as well.
  %% Syntax:
  %% \copyrigthtext{metadata text}{text visible on the page}
  %% 
  %% In the macro below, the text written in the metadata must have a \noexpand
  %% macro before the \copyright special character, and macros (\copyright and
  %% \year here) must be separated by the \ character (space chacter) from the
  %% text that follows. The macros in the argument of the \copyrighttext macro
  %% automatically insert the year and the author's name. (Note! \ThesisAuthor is
  %% an internal macro of the aaltothesis.cls class file).
  %% Of course, the same text could have simply been written as
  %% \copyrighttext{Copyright \noexpand\copyright\ 2018 Eddie Engineer}
  %% {Copyright \copyright{} 2018 Eddie Engineer}
  \copyrighttext{Copyright \noexpand\copyright\ \number\year\ \ThesisAuthor}
  {Copyright \copyright{} \number\year{} \ThesisAuthor}

  %% You can prevent LaTeX from writing into the xmpdata file (it contains all the 
  %% metadata to be written into the pdf file) by setting the writexmpdata switch
  %% to 'false'. This allows you to write the metadata in the correct format
  %% directly into the file thesistemplate.xmpdata.
  %\setboolean{writexmpdatafile}{false}

  %% All that is printed on paper starts here
  \begin{document}

  %% Create the coverpage
  \makecoverpage

  %% Typeset the copyright text.
  %% If you wish, you may leave out the copyright text from the human-readable
  %% page of the pdf file. This may seem like a attractive idea for the printed
  %% document especially if "Copyright (c) yyyy Eddie Engineer" is the only text
  %% on the page. However, the recommendation is to print this copyright text.
  \makecopyrightpage

  %% Note that when writting your thesis in English, place the English abstract
  %% first followed by the possible Finnish or Swedish abstract.

  %% Abstract text
  %% The text in the \thesisabstract macro is stored in the macro \abstractext, so
  %% you can use the text metadata abstract directly as follows:
  \begin{abstractpage}[english]
    \abstracttext{}
  \end{abstractpage}

  \newpage
  %% Abstract in Finnish.
  \thesistitle{Opinnäyteen otsikko}
  \supervisor{Prof.}
  \advisor{TkT}
  \degreeprogram{Tieto-, tietoliikenne- ja informaatiotekniikka}
  \major{Signaalin-, puheen- ja kielenkäsittely}
  %% The keywords need not be separated by \spc now.
  \keywords{}
  %% Abstract text
  \begin{abstractpage}[finnish]
    tiivistelmä tähän
  \end{abstractpage}

  %% Preface
  %% This section is optional. Remove it if you do not want a preface.
  \mysection{Preface}
  preface here

  \vspace{5cm}
  Otaniemi, 31.8.2018

  % \vspace{5mm}
  % {\hfill Eddie E.\ A.\ Engineer \hspace{1cm}}

  \newpage
  \thesistableofcontents
%%

%% Symbols and abbreviations 
  \mysection{Symbols and abbreviations}

  \subsection*{Symbols}

  \begin{tabular}{ll}
  % examples
  % $\mathbf{B}$  & magnetic flux density  \\
  % $c$              & speed of light in vacuum $\approx 3\times10^8$ [m/s]\\
  % $\omega_{\mathrm{D}}$    & Debye frequency \\
  % $\omega_{\mathrm{latt}}$ & average phonon frequency of lattice \\
  % $\uparrow$       & electron spin direction up\\
  % $\downarrow$     & electron spin direction down \\
  % /examples
  $\boldsymbol{\mu}$                          & mean vector of a GMM \\
  $\boldsymbol{\Sigma}$                       & covariance matrix of a GMM \\
  
  \end{tabular}

  \subsection*{Operators}

  % \begin{tabular}{ll}
  % examples
  % $\nabla \times \mathbf{A}$                  & curl of vectorin $\mathbf{A}$\\
  % $\displaystyle\frac{\mbox{d}}{\mbox{d} t}$  & derivative with respect to 
  %                                               variable $t$\\[3mm]
  % $\displaystyle\frac{\partial}{\partial t}$  & partial derivative with respect 
  %                                               to variable $t$ \\[3mm]
  % $\sum_i $                                   & sum over index $i$\\
  % $\mathbf{A} \cdot \mathbf{B}$               & dot product of vectors $\mathbf{A}$ and 
  %                                               $\mathbf{B}$ \\
  % /examples

  % \end{tabular}

  \subsection*{Abbreviations}

  \begin{tabular}{ll}
  % AC         & alternating current \\
  % APLAC      & an object-oriented analog circuit simulator and design tool \\
  %            & (originally Analysis Program for Linear Active Circuits) \\
  % BCS        & Bardeen-Cooper-Schrieffer \\ %% dash between the names
  % DC         & direct current \\
  % TEM        & transverse eletromagnetic
  AM            & acoustic model \\
  ASR           & automatic speech recognition \\
  CMVN          & cepstral mean and variance normalization \\
  fMLLR         & feature space maximum likelihood linear regression \\
  GMM           & Gaussian mixture model \\
  HMM           & hidden Markov model \\
  LDA           & linear discriminant analysis \\
  LM            & language model \\
  MFCC          & mel-frequency cepstral coefficient \\
  MLLT          & maximum likelihood linear transformation \\
  PDF           & probability density function \\
  SAT           & speaker adaptive training \\
  VTLN          & vocal tract length normalization \\
  \end{tabular}
%%

%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
\cleardoublepage

%% Text body begins.
\section{Introduction}


%% Leave page number of the first page empty
\thispagestyle{empty}
\clearpage

\section{Finnish conversations to text} 

  The task of converting speech into text, or "automatic speech recognition", can be divided into four subtasks: feature extraction, acoustic modelling, phoneme-to-grapheme mapping, and language modelling. The audio signal is first divided into $T$ segments, and the segments converted into feature vectors, or observations $\boldsymbol{O}=\boldsymbol{o}_1,...,\boldsymbol{o}_T$, which are a compressed, discrete representation of the audio signal. 
  The task is then to find $\argmax_{\boldsymbol{W}} P(\boldsymbol{W}|\boldsymbol{O})$, where $\boldsymbol{W}$ is a word sequence. This probability is not practicable to compute directly, but by Bayes' rule it can be expanded to 
  \begin{equation}\label{asr-bayes}
    \argmax_{\boldsymbol{W}} P(\boldsymbol{W}|\boldsymbol{O}) = 
    \argmax_{\boldsymbol{W}} \frac{P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})} {P(\boldsymbol{O})}
  \end{equation}

  The probability of the observations ${P(\boldsymbol{O})}$ is not relevant in finding the best transcription for the observations, which leaves the product $P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})$ to be estimated. Here, the former factor is the a priori probability of a word sequence, modelled by a language model. The acoustic model inputs the observations and outputs likelihoods of phoneme sequences, which are mapped to grapheme sequences by a lexicon (also called a dictionary), yielding $P(\boldsymbol{O}|\boldsymbol{W})}$.

  The first four sections in this chapter respectively describe the four components of the conventional ASR system. The last section (\ref{section:conv}) discusses the specifics of recognising conversational Finnish.

  %  A language model gives an a priori probability for each word sequence: $P(\boldsymbol{W})$. The estimate $\hat{\boldsymbol{W}}$ of the best transcription given the observations is the most likely sequence 

  % \begin{equation}\label{asr-bayes-argmax}
  %   \hat{\boldsymbol{W}} = \argmax_{\boldsymbol{W}} P(\boldsymbol{W}|\boldsymbol{O}) = 
  %   \argmax_{\boldsymbol{W}} \frac{P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})} {P(\boldsymbol{O})}
  % \end{equation} 

\subsection{Feature extraction} 

  A speech audio signal contains a lot of information that is irrelevant for converting the signal to text. The first step of ASR is to find the features of the signal that contain the information about what is being said. An assumption is made that the speech signal does not change meaningfully in a time frame of about 10 milliseconds, so that the signal can be divided into frames with this time resolution. The frames overlap so that each frame is about 20 or 25 milliseconds, and a tapered window function, such as Hamming, is applied to (i.e., multiplied by) each frame. This window function removes the discontinuities that occur in the borders of frames, and the overlapping compensates for the tapering of the window function so that the distorting effect on the signal statistics is minimised \citet{}. % https://wiki.aalto.fi/display/ITSP/Windowing
  The stationary frames' frequency components can be then computed with the Fourier transform. A commonly used method is to extract the MFCCs by applying a logarithmic mel-scale filterbank to the frequency spectrum, and lastly computing the DCT. The log mel-scale emphasises the lower frequencies emulating the way humans perceive sound, i.e., the way the human inner ear recognises lower frequencies with higher frequency resolution. The DCT decorrelates the coefficients so that the use of diagonal covariance matrices is possible in the subsequent stages of the modelling, namely when using GMMs.
  
  The MFCC method thus assumes that coefficients adjacent in time are independent of each other, which is a false assumption in the case of speech signals. This can be corrected for by adding additional information about how the signal changes in time to the features. 
  Information about temporal change and change of temporal change is extracted from the MFCCs by calculating the differences and second-order differences of adjacent coefficients. These features are also called the delta ($\boldsymbol{\Delta}$) and delta-delta ($\boldsymbol{\Delta\Delta}$) features, or speed and acceleration features. The $\boldsymbol{\Delta}$s and $\boldsymbol{\Delta\Delta}$s are concatenated with the MFCC vectors, increasing the feature vector length threefold.

  The cepstral mean and variance normalization is a method for making the features more useful in noisy conditions \citep{viikki1998cepstral}. In this technique, the MFCC feature vectors are normalised to have a zero mean and unit variance over a sliding finite segment. After the normalisation, clean and noisy MFCCs are more similar, which mitigates the performance reduction caused by noisy environments.

\subsection{Acoustic modelling} 
  In the conventional ASR system, used also in this thesis, phonemes are modelled by HMMs, which are then concatenated to model utterances.
  Hidden Markov models are based on the idea that a system goes through sequences of hidden states which cause observations. Each observation has a probability of being generated by each hidden state, and each hidden state pair has a transition probability $t_{ij}$ that describes how probable it is to move from state $i$ to state $j$. 

  % in Kaldi 
  % http://kaldi-asr.org/doc/hmm.html
  The typical HMM topology for a phoneme is a left-to-right model, also called the Bakis model, with three emitting states which each have a transition to the next state and a self-loop. The model also includes a fourth non-emitting final state which has no transitions out of it.

  % Gaussian mixtures
  A state's emission probabilities are represented by a PDF, typically a GMM whose parameters, i.e. its mean vector $\boldsymbol{\mu}$, covariance matrix $\boldsymbol{\Sigma}$ and mixture weights, are estimated in the model training process. An observed feature vector $\boldsymbol{o}_t$ is emitted from a certain state $i$ with an observation likelihood, which would in the case of a single component Gaussian be

  \[
    b_i(\boldsymbol{o}_t) = \frac{1}{\sqrt{(2 \pi)^n |\boldsymbol{\Sigma}_j|}} \\
      e^{\frac{1}{2}(\boldsymbol{o}_t - \boldsymbol{\mu}_j)^\top \\
      \boldsymbol{\Sigma}_j^{-1} \\
      (\boldsymbol{o}_t - \boldsymbol{\mu}_j)}
  \]

  The monophone models are first trained (with single-component Gaussians?) and the triphone models are initialised with the monophone model set parameters. The number of Gaussians in the triphone models is increased gradually and the parameters are re-estimated.

  % Baum-Welch algorithm
  The Baum-Welch algorithm is an expectation-maximisation algorithm for estimating the HMM paramters. The task is to maximise the likelihood of the means and variances of the HMM given the observations.



  % state tying
  The states of the phoneme HMMs are can be tied together so that the parameters of the output distributions of those states are shared. This makes the estimation of the parameters more robust because there are more training data occurences, and also makes the total system more compact with fewer parameters \citep{young1992general}. States are clustered based on some metric of similarity.   

  % phonetic decision trees
  % http://kaldi-asr.org/doc/tree_externals.html
  In tree-based clustering as described by \citet{young1994tree}, the states are divided into branches in a top-down optimisation procedure. Starting from the root node, the question that maximises the likelihood is selected for the node, with the data on each side of the divide being modelled by a single Gaussian.
  In a phonetic decision trees the questions are about the context of the phone, e.g. "Is the phone on the left of the current phone a fricative?". 

  After the procedure, the leaves of the tree are the state clusters in which the states are tied. In the final stage, leaves can be merged if the likelihood does not decrease more than a threshold value.

  After a tree has been constructed for the states of the triphone models, also previously unseen triphones can be synthesised by traversing the tree to the aprropriate leaf node, i.e. cluster, by answering the questions about that triphone's context and using the tied states of that cluster.


  % transition modelling
  The transition probabilities from a state to another are essentially the counts of the transitions seen in the training corpus.

  % alignments % lda + mllt
  % https://kaldi-asr.org/doc/transform.html
  Linear transformations can be applied either in model-space or feature-space \citep{gales1998maximum}. MLLT and LDA transfors are speaker-independent

  fMLLR transform is speaker- or utterance-specific.

  An alignments is a sequence of transitions that corresponds to an utterance. 

  Speaker adaptive training \citep{povey2008fast}

  % WFSTs

\subsection{Mapping phonemes to graphemes}

\subsection{Statistical language modelling}

\subsubsection{n-gram language models}

\subsubsection{Recurrent neural language models}

\subsubsection{Attention-based neural language models}

% \citet{dai2019transformer}

\subsection{Spoken and written conversations in Finnish} \label{section:conv}



\clearpage
\section{Methods}




\clearpage
\section{Experiments}

\subsection{Baseline}

The baseline language models and the ASR system is based on the systems developed by \citet{enarvi2017automatic}.





\clearpage
\section{Results}

\clearpage
\section{Conclusion} 


\clearpage
\bibliographystyle{apalike}
\bibliography{references}


% \thesisbibliography

% \begin{thebibliography}{99}

%% Alla pilkun j\"alkeen on pakotettu oikea v\"ali \<v\"alily\"onti>-merkeill\"a.
% \bibitem{Kauranen} Kauranen,\ I., Mustakallio,\ M. ja Palmgren,\ V.
%   \textit{Tutkimusraportin kirjoittamisen opas opinn\"aytety\"on
%     tekij\"oille.}  Espoo, Teknillinen korkeakoulu, 2006.

% \end{thebibliography}

%% Appendices
%% If you don't have appendices, remove \clearpage and \thesisappendix below.
% \clearpage
% \thesisappendix
% \section{}

\end{document}