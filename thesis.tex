%% License 
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  %% This is licensed under the terms of the MIT license below.                 %%
  %%                                                                            %%
  %% Written by Luis R.J. Costa.                                                %%
  %% Currently developed at the Learning Services of Aalto University School of %%
  %% Electrical Engineering by Luis R.J. Costa since May 2017.                  %%
  %%                                                                            %%
  %% Copyright 2017-2018, by Luis R.J. Costa, luis.costa@aalto.fi,              %%
  %% Copyright 2017-2018 Swedish translations in aaltothesis.cls by Elisabeth   %%
  %% Nyberg, elisabeth.nyberg@aalto.fi and Henrik Wallén,                       %%
  %% henrik.wallen@aalto.fi.                                                    %%
  %% Copyright 2017-2018 Finnish documentation in the template opinnatepohja.tex%%
  %% by Perttu Puska, perttu.puska@aalto.fi, and Luis R.J. Costa.               %%
  %% Copyright 2018 English template thesistemplate.tex by Luis R.J. Costa.     %%
  %% Copyright 2018 Swedish template kandidatarbetsbotten.tex by Henrik Wallen. %%
  %%                                                                            %%
  %% Permission is hereby granted, free of charge, to any person obtaining a    %%
  %% copy of this software and associated documentation files (the "Software"), %%
  %% to deal in the Software without restriction, including without limitation  %%
  %% the rights to use, copy, modify, merge, publish, distribute, sublicense,   %%
  %% and/or sell copies of the Software, and to permit persons to whom the      %%
  %% Software is furnished to do so, subject to the following conditions:       %%
  %% The above copyright notice and this permission notice shall be included in %%
  %% all copies or substantial portions of the Software.                        %%
  %% THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR %%
  %% IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,   %%
  %% FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL    %%
  %% THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER %%
  %% LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING    %%
  %% FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER        %%
  %% DEALINGS IN THE SOFTWARE.                                                  %%
  %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%

%% spellcheck-on

%% Configurations, meta information, prefaces etc. 
  \documentclass[english, 12pt, a4paper, elec, utf8, a-1b, hidelinks]{aaltothesis}
  %\documentclass[english, 12pt, a4paper, elec, utf8, a-1b]{aaltothesis}
  %\documentclass[english, 12pt, a4paper, elec, dvips, online]{aaltothesis}

  %% Use the following options in the \documentclass macro above:
  %% your school: arts, biz, chem, elec, eng, sci
  %% the character encoding scheme used by your editor: utf8, latin1
  %% thesis language: english, finnish, swedish
  %% make an archiveable PDF/A-1b or PDF/A-2b compliant file: a-1b, a-2b
  %%                    (with pdflatex, a normal pdf containing metadata is
  %%                     produced without the a-*b option)
  %% typeset in symmetric layout and blue hypertext for online publication: online
  %%            (no option is the default, resulting in a wide margin on the
  %%             binding side of the page and black hypertext)
  %% two-sided printing: twoside (default is one-sided printing)

  \usepackage{amsfonts, amssymb, amsbsy, amsmath, natbib, graphicx}

  \DeclareMathOperator*{\argmax}{argmax}

  % \university{Aalto-yliopisto}
  % \school{Sähkötekniikan korkeakoulu}
  \degreeprogram{Computer, Communication and Information Sciences}
  \major{Signal, Speech and Language Processing}
  \code{ELEC3031}
  \univdegree{MSc}
  \thesisauthor{Anssi Moisio}

  %% A possible "and" in the title should not be the last word in the line, it
  %% begins the next line.
  %% Specify the title again without the linebreak characters in the optional
  %% argument in box brackets. This is done because the title is part of the 
  %% metadata in the pdf/a file, and the metadata cannot contain linebreaks.
  \thesistitle{Automatic recognition of conversational speech} % working title
  %\thesistitle[Title of the thesis]{Title of\\ the thesis}
  \place{Espoo}
  \date{}

  %% Thesis supervisor
  %% Note the "\" character in the title after the period and before the space
  %% and the following character string.
  %% This is because the period is not the end of a sentence after which a
  %% slightly longer space follows, but what is desired is a regular interword
  %% space.
  \supervisor{Prof.\ Mikko Kurimo}

  %% Advisor(s)---two at the most---of the thesis.
  \advisor{Dr.}

  %% Aaltologo: syntax:
  %% \uselogo{aaltoRed|aaltoBlue|aaltoYellow|aaltoGray|aaltoGrayScale}{?|!|''}
  %% The logo language is set to be the same as the thesis language.
  \uselogo{aaltoRed}{''}

  %% The English abstract:
  %% All the details (name, title, etc.) on the abstract page appear as specified
  %% above.
  %% Thesis keywords:
  %% Note! The keywords are separated using the \spc macro
  \keywords{For keywords choose\spc concepts that are\spc central to your\spc thesis}

  %% The abstract text. This text is included in the metadata of the pdf file as well
  %% as the abstract page.
  \thesisabstract{abstract here
  }

  %% Copyright text. Copyright of a work is with the creator/author of the work
  %% regardless of whether the copyright mark is explicitly in the work or not.
  %% You may, if you wish, publish your work under a Creative Commons license (see
  %% creaticecommons.org), in which case the license text must be visible in the
  %% work. Write here the copyright text you want. It is written into the metadata
  %% of the pdf file as well.
  %% Syntax:
  %% \copyrigthtext{metadata text}{text visible on the page}
  %% 
  %% In the macro below, the text written in the metadata must have a \noexpand
  %% macro before the \copyright special character, and macros (\copyright and
  %% \year here) must be separated by the \ character (space chacter) from the
  %% text that follows. The macros in the argument of the \copyrighttext macro
  %% automatically insert the year and the author's name. (Note! \ThesisAuthor is
  %% an internal macro of the aaltothesis.cls class file).
  %% Of course, the same text could have simply been written as
  %% \copyrighttext{Copyright \noexpand\copyright\ 2018 Eddie Engineer}
  %% {Copyright \copyright{} 2018 Eddie Engineer}
  \copyrighttext{Copyright \noexpand\copyright\ \number\year\ \ThesisAuthor}
  {Copyright \copyright{} \number\year{} \ThesisAuthor}

  %% You can prevent LaTeX from writing into the xmpdata file (it contains all the 
  %% metadata to be written into the pdf file) by setting the writexmpdata switch
  %% to 'false'. This allows you to write the metadata in the correct format
  %% directly into the file thesistemplate.xmpdata.
  %\setboolean{writexmpdatafile}{false}

  %% All that is printed on paper starts here
  \begin{document}

  \pagenumbering{roman}

  %% Create the coverpage
  \makecoverpage

  %% Typeset the copyright text.
  %% If you wish, you may leave out the copyright text from the human-readable
  %% page of the pdf file. This may seem like a attractive idea for the printed
  %% document especially if "Copyright (c) yyyy Eddie Engineer" is the only text
  %% on the page. However, the recommendation is to print this copyright text.
  \makecopyrightpage

  %% Note that when writting your thesis in English, place the English abstract
  %% first followed by the possible Finnish or Swedish abstract.

  %% Abstract text
  %% The text in the \thesisabstract macro is stored in the macro \abstractext, so
  %% you can use the text metadata abstract directly as follows:
  \begin{abstractpage}[english]
    \abstracttext{}
  \end{abstractpage}

  \newpage
  %% Abstract in Finnish.
  \thesistitle{Opinnäyteen otsikko}
  \supervisor{Prof.}
  \advisor{TkT}
  \degreeprogram{Tieto-, tietoliikenne- ja informaatiotekniikka}
  \major{Signaalin-, puheen- ja kielenkäsittely}
  %% The keywords need not be separated by \spc now.
  \keywords{}
  %% Abstract text
  \begin{abstractpage}[finnish]
    tiivistelmä tähän
  \end{abstractpage}

  %% Preface
  %% This section is optional. Remove it if you do not want a preface.
  \mysection{Preface}
  preface here

  \vspace{5cm}
  Otaniemi, 31.8.2018

  % \vspace{5mm}
  % {\hfill Eddie E.\ A.\ Engineer \hspace{1cm}}

  \newpage
  \thesistableofcontents
%%

%% Symbols and abbreviations 
  \mysection{Symbols and abbreviations}

  \subsection*{Symbols}

  \begin{tabular}{ll}
  % examples
  % $\mathbf{B}$  & magnetic flux density  \\
  % $c$              & speed of light in vacuum $\approx 3\times10^8$ [m/s]\\
  % $\omega_{\mathrm{D}}$    & Debye frequency \\
  % $\omega_{\mathrm{latt}}$ & average phonon frequency of lattice \\
  % $\uparrow$       & electron spin direction up\\
  % $\downarrow$     & electron spin direction down \\
  % /examples
  $\boldsymbol{\mu}$                          & mean vector of a GMM \\
  $\boldsymbol{\Sigma}$                       & covariance matrix of a GMM \\

  $P(.)$        & probability \\
  $p(.|.)$        & likelihood \\
  
  \end{tabular}

  \subsection*{Operators}

  % \begin{tabular}{ll}
  % examples
  % $\nabla \times \mathbf{A}$                  & curl of vectorin $\mathbf{A}$\\
  % $\displaystyle\frac{\mbox{d}}{\mbox{d} t}$  & derivative with respect to 
  %                                               variable $t$\\[3mm]
  % $\displaystyle\frac{\partial}{\partial t}$  & partial derivative with respect 
  %                                               to variable $t$ \\[3mm]
  % $\sum_i $                                   & sum over index $i$\\
  % $\mathbf{A} \cdot \mathbf{B}$               & dot product of vectors $\mathbf{A}$ and 
  %                                               $\mathbf{B}$ \\
  % /examples

  % \end{tabular}

  \subsection*{Abbreviations}

  \begin{tabular}{ll}
  AM            & acoustic model \\
  ASR           & automatic speech recognition \\
  CER           & character error rate \\
  CMVN          & cepstral mean and variance normalization \\
  DNN           & deep neural network \\
  EM            & expectation maximisation \\
  fMLLR         & feature space maximum likelihood linear regression \\
  FST           & finite-state transducer \\
  GMM           & Gaussian mixture model \\
  HMM           & hidden Markov model \\
  LDA           & linear discriminant analysis \\
  LM            & language model \\
  LSTM          & long short-term memory \\
  MCE           & minimum classification error \\
  MFCC          & mel-frequency cepstral coefficient \\
  ML            & maximum likelihood \\
  MLLR          & maximum likelihood linear regression \\
  MLLT          & maximum likelihood linear transformation \\
  MMI           & maximum mutual information \\
  MPE           & minimum phone error \\
  NN            & neural network \\
  PDF           & probability density function \\
  SAT           & speaker adaptive training \\
  TDNN          & time delay neural network \\
  WER           & word error rate \\
  WFST          & weighted finite-state transducer \\
  VTLN          & vocal tract length normalization \\
  \end{tabular}
%%

%% \clearpage is similar to \newpage, but it also flushes the floats (figures
%% and tables).
\cleardoublepage
\pagenumbering{arabic}
\setcounter{page}{1}

%% Text body begins.
\section{Introduction}


%% Leave page number of the first page empty
\thispagestyle{empty}
\clearpage

\section{Finnish conversations to text} 

  The task of converting speech into text, or \emph{automatic speech recognition}, can be divided into
  % four
  subtasks: \emph{feature extraction}, \emph{acoustic modelling}, \emph{phoneme-to-grapheme mapping}, and \emph{language modelling}. The audio signal is first divided into $T$ segments, and the segments converted into feature vectors, also called observations, $\boldsymbol{O}=\boldsymbol{o}_1,...,\boldsymbol{o}_T$, which are a compressed, discrete representation of the audio signal. 
  The task is then to find $\argmax_{\boldsymbol{W}} P(\boldsymbol{W}|\boldsymbol{O})$, where $\boldsymbol{W}$ is a word sequence. This probability is not practicable to compute directly, but by Bayes' rule it can be expanded to 
  \begin{equation}\label{asr-bayes}
    \argmax_{\boldsymbol{W}} P(\boldsymbol{W}|\boldsymbol{O}) = 
    \argmax_{\boldsymbol{W}} \frac{P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})} {P(\boldsymbol{O})}
  \end{equation}

  The probability of the observations ${P(\boldsymbol{O})}$ is not relevant in finding the best transcription for the observations, which leaves the product $P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})$ to be estimated. Here, the former factor is the a priori probabilities of word sequences, modelled by a language model. The acoustic model determines likelihoods of observations given phoneme sequences that are mapped to grapheme sequences by a lexicon (also called a dictionary), yielding $P(\boldsymbol{O}|\boldsymbol{W})$.

  The first
  % four
  sections of this chapter respectively describe the
  % four
  components of the conventional ASR system. Section \ref{section:conv} discusses the specifics of recognising conversational Finnish.

  %  A language model gives an a priori probability for each word sequence: $P(\boldsymbol{W})$. The estimate $\hat{\boldsymbol{W}}$ of the best transcription given the observations is the most likely sequence 

  % \begin{equation}\label{asr-bayes-argmax}
  %   \hat{\boldsymbol{W}} = \argmax_{\boldsymbol{W}} P(\boldsymbol{W}|\boldsymbol{O}) = 
  %   \argmax_{\boldsymbol{W}} \frac{P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})} {P(\boldsymbol{O})}
  % \end{equation} 

\subsection{Feature extraction} 

  A speech audio signal contains a lot of information that is irrelevant for converting the signal to text. The first step of ASR is to find the features of the signal that contain the information about what is being said. An assumption is made that the speech signal does not change meaningfully in a time frame of about 10 milliseconds, so that the signal can be divided into frames with this time resolution. The frames overlap so that each frame is about 20 or 25 milliseconds, and a tapered window function, such as Hamming, is applied to (i.e., multiplied by) each frame. This window function removes the discontinuities that occur on the borders of frames, and the overlapping compensates for the tapering of the window function so that the distorting effect on the signal statistics is minimised \citet{}. % https://wiki.aalto.fi/display/ITSP/Windowing

  The stationary frames' frequency components can be then computed with the Fourier transform. A commonly used method is to extract the MFCCs by applying a logarithmic mel-scale filterbank to the frequency spectrum, and lastly computing the DCT. The log mel-scale emphasises the lower frequencies emulating the way humans perceive sound, i.e., the way the human inner ear recognises lower frequencies with higher frequency resolution. The DCT decorrelates the coefficients so that the use of diagonal covariance matrices is possible in the subsequent stages of the modelling, namely when using GMMs.
  
  The MFCC method thus assumes that coefficients adjacent in time are independent of each other, which is a false assumption in the case of speech signals. This can be corrected for by adding additional information to the features about how the signal changes in time. 
  Information about temporal change and change of temporal change is extracted from the MFCCs by calculating the differences and second-order differences of adjacent coefficients. These features are also called the delta ($\boldsymbol{\Delta}$) and delta-delta ($\boldsymbol{\Delta\Delta}$), or acceleration, features. 
  % The $\boldsymbol{\Delta}$s and $\boldsymbol{\Delta\Delta}$s are concatenated with the MFCC vectors, increasing the feature vector length threefold.
  The delta feature vector $\boldsymbol{\Delta}_t$ corresponding to the MFCC vector $\boldsymbol{c}_t$ (or the time step if that vector) is calculated by subtracting the weighted previous vector(s) from the weighted subsequent vectors and normalising the sum:
  \begin{equation}
  \boldsymbol{\Delta}_t = \frac{\sum_{\theta=1}^{\Theta}
  \theta(\boldsymbol{c}_{t+\theta}-\boldsymbol{c}_{t-\theta})}{2\sum_{\theta=1}^{\Theta}\theta^2}
  \end{equation}
  In Kaldi, the default window length $\boldsymbol{\Theta}$ is 2, so the $\boldsymbol{\Delta}$s are computed by multiplying the MFCCs with a sliding window of values $[-2,-1,0,1,2]$ and then normalising by dividing by $2*(1^2 + 2^2)= 10$ \citep{kaldi}. The $\boldsymbol{\Delta\Delta}$s are computed by applying the same method to the $\boldsymbol{\Delta}$ features. The first and last MFCCs are replicated to fill the window \citep{htkbook}.

  The cepstral mean and variance normalization is a method for making the features more useful in noisy conditions \citep{viikki1998cepstral}. In this technique, the MFCC feature vectors are normalised to have a zero mean and unit variance over a sliding finite segment. After the normalisation, clean and noisy MFCCs are more similar, which mitigates the performance reduction caused by noisy environments.

\subsection{Acoustic modelling} 

\subsubsection{Modelling phonemes with hidden Markov models}

  Estimating the likelihoods of observations given phonemes is achieved by creating a HMM for each phoneme. This way the task becomes to estimate the parameters of the HMMs.
  After the HMMs are trained, likelihoods of the observed sequences given the phoneme-specific HMMs can be used to map observations to phonemes.
  % In the conventional ASR system, used also in this thesis, phonemes are modelled by HMMs, which are then concatenated to model utterances.

  A hidden Markov model consists of a hidden Markov chain, also called regime, and the observation sequence, i.e., feature vectors. Each observation $\boldsymbol{o}_t$ has a probability $b_i(\boldsymbol{o}_t)$ of being generated by a hidden state $i$. In other words, the observation is a probabilistic function of the hidden state. 
  % Gaussian mixtures
  A state's emission probabilities are represented by a PDF, typically a GMM 
  \begin{equation}\label{}
    b_i(\boldsymbol{o}_t) = \sum^{M_j}_{m=1}c_{jm}
      \mathcal{N}(\boldsymbol{o}_t ; \boldsymbol{\mu}_{jm}, \boldsymbol{\Sigma}_{jm})
  \end{equation}
  where $\boldsymbol{\mu}$ is the mean vector, $\boldsymbol{\Sigma}$ is the covariance matrix  and $c_{jm}$ is mixture weight for state j. The Gaussian mixture density is
  \begin{equation}\label{}
    \mathcal{N}(\boldsymbol{o} ; \boldsymbol{\mu}, \boldsymbol{\Sigma})
       = \frac{1}{\sqrt{(2 \pi)^n |\boldsymbol{\Sigma}|}} 
      e^{-\frac{1}{2}(\boldsymbol{o} - \boldsymbol{\mu})^\top 
      \boldsymbol{\Sigma}^{-1} 
      (\boldsymbol{o} - \boldsymbol{\mu})}
  \end{equation}

  HMMs are used to model sequences, but observations are independent of past observations. Instead, the regime has a memory, although the shortest possible: the probability of being a certain state in the next time step depends only on the current state and not the previous states. This is called the Markov assumption. Each hidden state pair (an arc from a state to another) is associated with a transition probability $a_{ij}$ that describes how probable it is to move from state $i$ to state $j$. 

  A HMM is defined by ...

  

  % in Kaldi 
  % http://kaldi-asr.org/doc/hmm.html
  The typical HMM topology for a phoneme is a left-to-right model, also called the Bakis model, with three emitting states which each have a transition to the next state and a self-loop. The model also includes a fourth non-emitting final state which has no transitions out of it. After initialising a HMM for each phoneme, the parameters, i.e. means, covariances and mixture weights need to be estimated in the training process.

\subsubsection{Training HMMs and finding the best hidden state sequence}

  % Baum-Welch algorithm
  The Baum-Welch algorithm is an expectation-maximisation algorithm for estimating the HMM paramters. Maximising the expectedness of the data could be turned around and thought of as minimising how suprising the training data are to the model by modifying the model. Expectation maximisation is an iterative method to find the maximum likelihood of a set of data given a model. Here, the task is to maximise the likelihood $P(\boldsymbol{O}|M)$ of the observations $\boldsymbol{O}$  given the means and variances of the HMM $M$. 
  The training starts with some trial values of the parameters 

  \begin{equation}\label{eq:mu_hat}
    \hat{\boldsymbol{\mu}}_j = \frac{\sum^T_{t=1}L_j(t)\boldsymbol{o}_t}
      {\sum^T_{t=1}L_j(t)}
  \end{equation}

  \begin{equation}\label{eq:sigma_hat}
    \hat{\boldsymbol{\Sigma}}_j = \frac{\sum^T_{t=1}L_j(t)
      (\boldsymbol{o}_t - \boldsymbol{\mu}_j)
      (\boldsymbol{o}_t - \boldsymbol{\mu}_j)^\top }
      {\sum^T_{t=1}L_j(t)}
  \end{equation}

  % , for which the likelihood is calculated, given each training example.
  
  The state occupation probability
  \begin{equation}\label{eq:occ}
    L_j(t) = P(x(t)=j|\boldsymbol{O},M),
  \end{equation}
  i.e., the probability of being in state $j$ at time $t$, is calculated using using the forward-backward algorithm. The forward probability $\alpha_j(t)$ and backward probability $\beta_j(t)$ are defined as 
  \begin{align}
    \alpha_j(t) &= P(\boldsymbol{o}_1,...,\boldsymbol{o}_t,x(t)=j|M)  \label{eq:forward} \\
    \beta_j(t) &= P(\boldsymbol{o}_{t+1},...,\boldsymbol{o}_T|x(t)=j,M) \label{eq:back}
  \end{align}
  Spelled out, $\aplha_j(t)$ is the probability of the partial observation sequence up till time $t$ and that $M$ is in state $j$ at the time step. The backward probability is the probability of the partial observation sequence at the subsequent time steps up till the last vector, given that at the current time the model state is $j$. 
  The forward probability is a joint probability of the observations and the state, whereas the backward probability of the observations is conditional on the state. This allows for the state occupation probability to be determined by the product of the forward and backward probabilities (from Eqs. \ref{eq:occ} \ref{eq:forward} and \ref{eq:back})
  \begin{align}\label{}
    L_j(t) = \frac{ \alpha_j(t) \beta_j(t) }{P(\boldsymbol{O}|M)}
  \end{align}
  
  $\alpha$ and $\beta$ are calculated respectively using the recursions
  \begin{align}
    \alpha_j(t) &= \bigg[ \sum^{N-1}_{i=2}\alpha_i(t-1)a_{ij} \bigg] b_j(\boldsymbol{o}_t)
    \label{eq:alpha_recurs} \\
    \beta_i(t) &= \sum^{N-1}_{j=2} \beta_j(t+1) a_{ij} b_j(\boldsymbol{o}_{t+1}) 
    \label{eq:beta_recurs}
  \end{align}
  and the initial conditions,
  \begin{align}
    \alpha_1(1) &= 1, \; \; \; \; \alpha_j(1) = a_{ij} b_j(\boldsymbol{o}_1) 
    \label{eq:alpha_init} \\
    \beta_i(T) &= a_{iN} \label{eq:beta_init}
  \end{align}
  for $1<j<N$ and the final conditions
  \begin{align}
    \alpha_N(T) &= \sum^{N-1}_{i=2}\alpha_i(T)a_{iN} \label{eq:afinal} \\
    \beta_1(1) &= \sum^{N-1}_{j=2} a_{1j} b_j(\boldsymbol{o}_1) \beta_j(1) \label{eq:bfinal}
  \end{align}
  where the limits of the sums exclude the states $1$ and $N$ because they are non-emitting. The recursion \ref{eq:alpha_recurs} calculates the forward probabilities (of seeing the specified observations and being at the state $j$) by summing all possible forward probabilities for all possible predecessor states $i$ weighted by the transition probability $a_{ij}$.

  From \ref{eq:forward}, \ref{eq:afinal} and \ref{eq:bfinal} it follows that calcualting the forward probability also yields the total likelihood $P(\boldsymbol{O}|M)=\alpha_N(T)$.

  % Viterbi training
  An alternative approach to the B-W algorithm is an iterative procedure called Viterbi training, also called Viterbi extraction or Baum-Viterbi algorithm since it involves the Baum re-estimation (Eqs. \label{eq:mu_hat} and \label{eq:sigma_hat}) and the Viterbi algorithm \citep{lember2008adjusted}. Instead of maximising the likelihood of all the data as in Eq. \ref{eq:alpha_recurs}, in VT the probability of only the most likely hidden sequence is maximised
  \begin{equation}
    \phi_N(T) = \max_i \{ \phi_i(T)a_{iN} \}
  \end{equation}
  for $1<i<N$ where
  \begin{equation}
    \phi_j(t) = \max_i \{ \phi_i(t-1)a_{ij} \} b_j(\boldsymbol{o}_t)
  \end{equation}
  and initially
  \begin{align}
    &\phi_1(1) = 1 \\
    &\phi_j(1) = a_{1j}b_j(\boldsymbol{o}_t).
  \end{align}
  for $1<j<N$. This alignment process finds an arc $ij$ for each observation $\boldsymbol{o}_t$ so that the last

  This results in an approximation of the maximum likelihood estimate (which was computed in the B-W algorithm)
  % ?
  .
  The Viterbi training is computationally less expensive than the B-W algorithm.
  In Viterbi training, the HMM parameters and the most probable hidden state sequence, both unknown, are estimated alternately. After updating the HMM parameters, the training data observations are aligned with the states, and within each state, a further alignment is made to align observations with mixture components. 
  % Using the Viterbi algorithm, the states are aligned with the observation sequence by maximising



  % AS stated in the Kaldi documentation, computed alignment is a sequence of transitions that corresponds to an utterance. 



\subsubsection{Phones in context}
  Phones of the same phoneme sound different when flanked by different phonemes. For this reason, contextual information is modelled, too, by assigning each triphone a HMM. 
  The monophone models are first trained
  % (with single-component Gaussians?)
  and the triphone models are initialised with the monophone model set parameters. The number of Gaussians in the triphone models is increased gradually and the parameters are re-estimated.

  % transition modelling
  % The transition probabilities from a state to another are essentially the counts of the transitions seen in the training corpus.



\subsubsection{State tying and phonetic decision trees}
  % tying
  The states of the phoneme HMMs are can be tied together so that the parameters of the output distributions of those states are shared. This makes the estimation of the parameters more robust because there are more training data occurences, and also makes the total system more compact with fewer parameters \citep{young1992general}. States are clustered based on some metric of similarity.  

  % http://kaldi-asr.org/doc/tree_externals.html
  In tree-based clustering as described by \citet{young1994tree}, the states are divided into branches in a top-down optimisation procedure. Starting from the root node, the question that maximises the likelihood is selected for the node, with the data on each side of the divide being modelled by a single Gaussian.
  In a phonetic decision trees the questions are about the context of the phone, e.g. "Is the phone on the left of the current phone a fricative?". 

  After the procedure, the leaves of the tree are the state clusters in which the states are tied. In the final stage, leaves can be merged if the likelihood does not decrease more than a threshold value.

  After a tree has been constructed for the states of the triphone models, also previously unseen triphones can be synthesised by traversing the tree to the aprropriate leaf node, i.e. cluster, by answering the questions about that triphone's context and using the tied states of that cluster.


\subsubsection{Adaptive training}
  % alignments % lda + mllt
  % https://kaldi-asr.org/doc/transform.html
  
  Linear transformations can be applied either in model-space or feature-space \citep{gales1998maximum}. MLLT and LDA transfors are speaker-independent

  fMLLR transform is speaker- or utterance-specific.

  % Speaker adaptive training \citep{povey2008fast}


\subsubsection{Discriminative training}

The maximum likelihood method aims to create a model that predicts the training data by determining a probability distribution over the feature space, i.e., over all possible observations. This is called generative training since the distribution can be sampled for predictions. However, the ability to produce examples of the modelled data is redundant in classification tasks. In discriminative training, instead of maximising the likelihood of the data given a generative model, a model is trained for discriminating between training examples. 
% Typically?
Discriminative training is based on an objective function which is minimised or maximised using an optimisation algorithm. The objective function can be simply the difference between the correct classifications (e.g., a phoneme sequence) for a set of examples and the classifications assigned to them by the model. This is called the minimum classification error (MCE) criterion.
Another type of objective function is the maximum mutual information (MMI) criterion
\begin{equation} \label{eq:mmi}
  \mathcal{F}_{\textup{MMI}}(M) = \sum_{r=1}^R \log 
    \frac{P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})}
      {\sum P(\boldsymbol{W})P(\boldsymbol{O}|\boldsymbol{W})}
\end{equation}








\subsubsection{Deep neural networks for acoustic modelling}

\subsubsection{Speaker identification}



% \subsection{Mapping phonemes to graphemes}



\subsection{Statistical language modelling}

\subsubsection{n-gram language models}

\subsubsection{Recurrent neural language models}

\subsubsection{Attention-based neural language models}

% \citet{dai2019transformer}



\subsection{Weighted finite-state transducers in ASR systems}


\subsection{Spoken and written conversations in Finnish} \label{section:conv}



\clearpage
\section{Methods}




\clearpage
\section{Experiments}

\subsection{Baseline}

The baseline language models and the ASR system is based on the systems developed by \citet{enarvi2017automatic}.





\clearpage
\section{Results}

\clearpage
\section{Conclusion} 


\clearpage
% for counting pages
\thesisbibliography

\bibliographystyle{apalike}
\bibliography{references}


% \begin{thebibliography}{99}

%% Alla pilkun j\"alkeen on pakotettu oikea v\"ali \<v\"alily\"onti>-merkeill\"a.
% \bibitem{Kauranen} Kauranen,\ I., Mustakallio,\ M. ja Palmgren,\ V.
%   \textit{Tutkimusraportin kirjoittamisen opas opinn\"aytety\"on
%     tekij\"oille.}  Espoo, Teknillinen korkeakoulu, 2006.

% \end{thebibliography}

%% Appendices
%% If you don't have appendices, remove \clearpage and \thesisappendix below.
% \clearpage
% \thesisappendix
% \section{}

\end{document}